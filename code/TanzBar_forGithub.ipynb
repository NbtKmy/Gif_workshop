{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        "\n",
        "The most part of this code is written by Wen Liu and Zhixin Piao, Min Jie, Wenhan Luo, Lin Ma and Shenghua Gao. They developed also the Liquid Warping GAN.\n",
        "The original code is in their Github repository [iPERDance/iPERCore](https://github.com/iPERDance/iPERCore)."
      ],
      "metadata": {
        "id": "dHhsUDpMo7PB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFLXe4HasHgr"
      },
      "source": [
        "## GPU usage\n",
        "Make sure that your runtime type is 'Python 3.6+ with GPU acceleration'. To do so, go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPl00TgplS-",
        "outputId": "33ba04f5-a2ce-4758-ffcc-51407f4f9107"
      },
      "source": [
        "# Install ffmpeg (ffprobe)\n",
        "!apt-get install ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45P7Uicpsuc",
        "outputId": "bf5d63fc-9465-4018-e151-a1870f9aeefd"
      },
      "source": [
        "# set CUDA_HOME, here we use CUDA 10.1\n",
        "import os\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-10.1\"\n",
        "\n",
        "!echo $CUDA_HOME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6oiRq1xKvm",
        "outputId": "41869bd0-2a6e-45da-b7a4-4569be3d6f19"
      },
      "source": [
        "!git clone https://github.com/iPERDance/iPERCore.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iPERCore'...\n",
            "remote: Enumerating objects: 890, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 890 (delta 9), reused 6 (delta 2), pack-reused 864\u001b[K\n",
            "Receiving objects: 100% (890/890), 23.04 MiB | 12.67 MiB/s, done.\n",
            "Resolving deltas: 100% (327/327), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9-b45uwx4f"
      },
      "source": [
        "## Setup iPERCore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aXNebVxv72E",
        "outputId": "6b024f3a-c50a-44fd-973a-3c245c36071e"
      },
      "source": [
        "cd /content/iPERCore/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iPERCore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZAZlLRHH2lq",
        "outputId": "b946289e-66cb-4d6a-938f-569c8719fa51"
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda version is 10.1\n",
            "/usr/bin/python3 -m pip install pip==20.2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip==20.2.4\n",
            "  Downloading pip-20.2.4-py2.py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 35.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pip-tools 6.2.0 requires pip>=20.3, but you have pip 20.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-20.2.4\n",
            "/usr/bin/python3 -m pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.3 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (1.21.6)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you'll have torch 1.7.0+cu101 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you'll have torch 1.7.0+cu101 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you'll have torch 1.7.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0+cu101\n",
            "/usr/bin/python3 -m pip install torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torchvision==0.8.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (1.21.6)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "fastai 2.7.9 requires torchvision>=0.8.2, but you'll have torchvision 0.8.1+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torchvision-0.8.1+cu101\n",
            "/usr/bin/python3 -m pip install mmcv-full==1.2.0 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html\n",
            "Collecting mmcv-full==1.2.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/mmcv_full-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (1.21.6)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (6.0)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 23.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.2.0) (7.1.2)\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.2.0 yapf-0.32.0\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "/usr/bin/python3 -m pip install scipy>=1.5.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.5.2) (1.21.6)\n",
            "/usr/bin/python3 -m pip install scikit-image>=0.17.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.21.6)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (1.7.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.15.0)\n",
            "/usr/bin/python3 -m pip install opencv-python>=4.4.0.40\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python>=4.4.0.40 in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.4.0.40) (1.21.6)\n",
            "/usr/bin/python3 -m pip install tensorboardX>=2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX>=2.1\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX>=2.1) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "/usr/bin/python3 -m pip install tqdm>=4.48.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "/usr/bin/python3 -m pip install visdom>=0.1.8.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visdom>=0.1.8.9\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (23.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.9) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.9) (1.24.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=0cc465b67ea2bf837417d5dcf4a02347a949561c9f16888d72dc16df3009ab33\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=a0fa56161ea917a1714998f7f8acdecd37fb3bc0a503d0f03488c10cc1a87753\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.3 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.4.1\n",
            "/usr/bin/python3 -m pip install easydict>=1.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easydict>=1.9 in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "/usr/bin/python3 -m pip install toml>=0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "  Cloning https://github.com/open-mmlab/mmdetection.git (to revision 8179440ec5f75fe95484854af61ce6f6279f3bbc) to /tmp/pip-req-build-33q41hxj\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (3.2.2)\n",
            "Collecting mmpycocotools\n",
            "  Downloading mmpycocotools-12.0.3.tar.gz (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.6.0) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.6.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools->mmdet==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from mmpycocotools->mmdet==2.6.0) (0.29.32)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.6.0) (4.1.1)\n",
            "Building wheels for collected packages: mmdet, mmpycocotools\n",
            "  Building wheel for mmdet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmdet: filename=mmdet-2.6.0-py3-none-any.whl size=490171 sha256=49c81a12d93dbdf3dee7b2a3330da815518c2d06026365c013beb9cb78ad4ff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/07/c9/55f832a7f1740f48e9ef244ed2b15d6bb042b75244ce041edd\n",
            "  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl size=265539 sha256=9a562584492efeae44a5fa068eaa3b23062d626d02263628773a957e9f18eae4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/4a/067979eccddf6a22b46722493df8e07b0541956a5ab5bac8b1\n",
            "Successfully built mmdet mmpycocotools\n",
            "Installing collected packages: mmpycocotools, terminaltables, mmdet\n",
            "Successfully installed mmdet-2.6.0 mmpycocotools-12.0.3 terminaltables-3.1.10\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "  Cloning https://github.com/open-mmlab/mmediting (to revision d4086aaf8a36ae830f1714aad585900d24ad1156) to /tmp/pip-req-build-m33kvh2w\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.99)\n",
            "Requirement already satisfied: mmcv-full>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.18.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (2.8.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmedit==0.5.0) (0.32.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (4.6.0.66)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (1.21.6)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (1.7.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mmedit==0.5.0) (2021.11.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (1.48.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->mmedit==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (3.0.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (1.3.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->mmedit==0.5.0) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->mmedit==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->mmedit==0.5.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->mmedit==0.5.0) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->mmedit==0.5.0) (4.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (4.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard->mmedit==0.5.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.8.1)\n",
            "Building wheels for collected packages: mmedit\n",
            "  Building wheel for mmedit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmedit: filename=mmedit-0.5.0-py2.py3-none-any.whl size=220163 sha256=1a6d4a47f5c597dfac6d2de76925113ef22efe620b69f622835c9c8dce8366c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/96/40/2b20e71f449b7769d9626c6197c4e10693fa5853b7345f9bdd\n",
            "Successfully built mmedit\n",
            "Installing collected packages: mmedit\n",
            "Successfully installed mmedit-0.5.0\n",
            "/usr/bin/python3 -m pip install git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "  Cloning https://github.com/iPERDance/neural_renderer.git (to revision e5f54f71a8941acf372514eb92e289872f272653) to /tmp/pip-req-build-2ltuhms7\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (0.8.1+cu101)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (4.64.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from neural-renderer==1.1.3) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->neural-renderer==1.1.3) (0.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->neural-renderer==1.1.3) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.15.0)\n",
            "Building wheels for collected packages: neural-renderer\n",
            "  Building wheel for neural-renderer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neural-renderer: filename=neural_renderer-1.1.3-cp37-cp37m-linux_x86_64.whl size=5684525 sha256=dd244e5d1b33679cb3c73dc3ffc949a629668438b539abb894c778d06a28f2d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/62/a4/71ebf253f9481f653ec789c5e0ac11c14a31fac223001a7a3f\n",
            "Successfully built neural-renderer\n",
            "Installing collected packages: neural-renderer\n",
            "Successfully installed neural-renderer-1.1.3\n",
            "running develop\n",
            "running egg_info\n",
            "creating iPERCore.egg-info\n",
            "writing iPERCore.egg-info/PKG-INFO\n",
            "writing dependency_links to iPERCore.egg-info/dependency_links.txt\n",
            "writing entry points to iPERCore.egg-info/entry_points.txt\n",
            "writing requirements to iPERCore.egg-info/requires.txt\n",
            "writing top-level names to iPERCore.egg-info/top_level.txt\n",
            "writing manifest file 'iPERCore.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'iPERCore.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/iPERCore.egg-link (link to .)\n",
            "Adding iPERCore 0.2.0 to easy-install.pth file\n",
            "Installing run_imitator script to /usr/local/bin\n",
            "Installing run_swapper script to /usr/local/bin\n",
            "Installing run_viewer script to /usr/local/bin\n",
            "\n",
            "Installed /content/iPERCore\n",
            "Processing dependencies for iPERCore==0.2.0\n",
            "Searching for toml==0.10.2\n",
            "Best match: toml 0.10.2\n",
            "Adding toml 0.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for easydict==1.9\n",
            "Best match: easydict 1.9\n",
            "Adding easydict 1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for visdom==0.1.8.9\n",
            "Best match: visdom 0.1.8.9\n",
            "Adding visdom 0.1.8.9 to easy-install.pth file\n",
            "Installing visdom script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboardX==2.5.1\n",
            "Best match: tensorboardX 2.5.1\n",
            "Adding tensorboardX 2.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opencv-python==4.6.0.66\n",
            "Best match: opencv-python 4.6.0.66\n",
            "Adding opencv-python 4.6.0.66 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-image==0.18.3\n",
            "Best match: scikit-image 0.18.3\n",
            "Adding scikit-image 0.18.3 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchfile==0.1.0\n",
            "Best match: torchfile 0.1.0\n",
            "Adding torchfile 0.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tornado==5.1.1\n",
            "Best match: tornado 5.1.1\n",
            "Adding tornado 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for websocket-client==1.4.1\n",
            "Best match: websocket-client 1.4.1\n",
            "Adding websocket-client 1.4.1 to easy-install.pth file\n",
            "Installing wsdump script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonpatch==1.32\n",
            "Best match: jsonpatch 1.32\n",
            "Adding jsonpatch 1.32 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyzmq==23.2.1\n",
            "Best match: pyzmq 23.2.1\n",
            "Adding pyzmq 23.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyWavelets==1.3.0\n",
            "Best match: PyWavelets 1.3.0\n",
            "Adding PyWavelets 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for imageio==2.9.0\n",
            "Best match: imageio 2.9.0\n",
            "Adding imageio 2.9.0 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for networkx==2.6.3\n",
            "Best match: networkx 2.6.3\n",
            "Adding networkx 2.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tifffile==2021.11.2\n",
            "Best match: tifffile 2021.11.2\n",
            "Adding tifffile 2021.11.2 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.6.15\n",
            "Best match: certifi 2022.6.15\n",
            "Adding certifi 2022.6.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for jsonpointer==2.3\n",
            "Best match: jsonpointer 2.3\n",
            "Adding jsonpointer 2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.4\n",
            "Best match: kiwisolver 1.4.4\n",
            "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for iPERCore==0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1DYsa76zvMY"
      },
      "source": [
        "# Download assets\n",
        "The assets contain all pre-trained models (**checkpoints.zip**), and other executable files (**executables.zip**, this one is only used for Windows. Linux ignores it), such as ffmpeg and ffprobe.\n",
        "\n",
        "Download links: \n",
        "  - checkpoints: http://101.32.75.151:12345/iper_plus_plus_latest_checkpoints.zip\n",
        "  - samples: http://101.32.75.151:12345/iper_plus_plus_latest_samples.zip\n",
        "\n",
        "You can manually download the **checkpoints.zip**, unzip it, and mv the **checkpoints** (as well as the **samples**) to **assets** folder. \n",
        "\n",
        " Otherwise, you can just run the following scripts to automaticially do these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFnPDBHN5WO",
        "outputId": "8a231a4d-649e-4c41-b67c-0e141f9dfe3e"
      },
      "source": [
        "# Download all checkpoints\n",
        "#!wget -O assets/checkpoints.zip \"https://1drv.ws/u/s!AjjUqiJZsj8whLkwQyrk3W9_H7MzNA?e=rRje0G\"\n",
        "!wget -O assets/checkpoints.zip \"http://101.32.75.151:12345/iper_plus_plus_latest_checkpoints.zip\"\n",
        "!unzip -o assets/checkpoints.zip -d assets/\n",
        "\n",
        "!rm assets/checkpoints.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 14:50:51--  http://101.32.75.151:12345/iper_plus_plus_latest_checkpoints.zip\n",
            "Connecting to 101.32.75.151:12345... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: ./iper_plus_plus_1.0.0_checkpoints.zip [following]\n",
            "--2022-09-22 14:50:51--  http://101.32.75.151:12345/iper_plus_plus_1.0.0_checkpoints.zip\n",
            "Reusing existing connection to 101.32.75.151:12345.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://101.32.75.151:10086/assets/checkpoints.zip [following]\n",
            "--2022-09-22 14:50:51--  http://101.32.75.151:10086/assets/checkpoints.zip\n",
            "Connecting to 101.32.75.151:10086... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.dm.files.1drv.com/y4mxbnSmmk5Aa-dOoCOinphLBAEF6gmKOKwe7kpXZrdebnEZS9Ihb4wYDtJ2V3ejvkcnFzvUh6c5s0Do8ILsA47yR5A9g_y3ySq9EjF633LZEJnO-Gi11xMQHllz0JdzRpl3K89dzNvng_-e4_-paZ7Nv-JHlKPc5VGAnyfiBbsmbSw_1denBb1bbK0xlDNvl9k7NJzL75wpRAdhpOsvmwpWk5fB9Z_gtznYb2BTGClNC7oF1aALNPF8IEoAiJpUhOO [following]\n",
            "--2022-09-22 14:50:52--  https://public.dm.files.1drv.com/y4mxbnSmmk5Aa-dOoCOinphLBAEF6gmKOKwe7kpXZrdebnEZS9Ihb4wYDtJ2V3ejvkcnFzvUh6c5s0Do8ILsA47yR5A9g_y3ySq9EjF633LZEJnO-Gi11xMQHllz0JdzRpl3K89dzNvng_-e4_-paZ7Nv-JHlKPc5VGAnyfiBbsmbSw_1denBb1bbK0xlDNvl9k7NJzL75wpRAdhpOsvmwpWk5fB9Z_gtznYb2BTGClNC7oF1aALNPF8IEoAiJpUhOO\n",
            "Resolving public.dm.files.1drv.com (public.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to public.dm.files.1drv.com (public.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243286164 (1.2G) [application/zip]\n",
            "Saving to: ‘assets/checkpoints.zip’\n",
            "\n",
            "assets/checkpoints. 100%[===================>]   1.16G  19.6MB/s    in 67s     \n",
            "\n",
            "2022-09-22 14:51:59 (17.8 MB/s) - ‘assets/checkpoints.zip’ saved [1243286164/1243286164]\n",
            "\n",
            "Archive:  assets/checkpoints.zip\n",
            "   creating: assets/checkpoints/\n",
            "   creating: assets/checkpoints/detection/\n",
            "  inflating: assets/checkpoints/detection/point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth  \n",
            "   creating: assets/checkpoints/inpainting/\n",
            "  inflating: assets/checkpoints/inpainting/deepfillv2_256x256_8x2_places_20200619-10d15793.pth  \n",
            "   creating: assets/checkpoints/losses/\n",
            "  inflating: assets/checkpoints/losses/sphere20a_20171020.pth  \n",
            "  inflating: assets/checkpoints/losses/vgg19-dcbb9e9d.pth  \n",
            "   creating: assets/checkpoints/mattors/\n",
            "  inflating: assets/checkpoints/mattors/exp-schp-lip.pth  \n",
            "  inflating: assets/checkpoints/mattors/gca_r34_4x10_200k_comp1k_SAD-34.77_20200604_213848-4369bea0.pth  \n",
            "   creating: assets/checkpoints/neural_renders/\n",
            "  inflating: assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth  \n",
            "   creating: assets/checkpoints/pose2d/\n",
            "  inflating: assets/checkpoints/pose2d/mobilenet_body18.pth  \n",
            "  inflating: assets/checkpoints/pose2d/openpose_body25.pth  \n",
            "   creating: assets/checkpoints/pose3d/\n",
            "  inflating: assets/checkpoints/pose3d/front_body.json  \n",
            "  inflating: assets/checkpoints/pose3d/front_facial.json  \n",
            "  inflating: assets/checkpoints/pose3d/gmm_08.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/head.json  \n",
            "  inflating: assets/checkpoints/pose3d/mapper_fim_enc.txt  \n",
            "  inflating: assets/checkpoints/pose3d/mapper_uv.txt  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_faces.npy  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_model.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_model_with_hand_v2.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_part_info.json  \n",
            "  inflating: assets/checkpoints/pose3d/spin_ckpt.pth  \n",
            "   creating: assets/checkpoints/restorers/\n",
            "  inflating: assets/checkpoints/restorers/esrgan_psnr_x4c64b23g32_1x16_1000k_div2k_20200420-bf5c993c.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_QjX1FzsEQI",
        "outputId": "c8a375e4-ab00-4d6b-ec2f-242b346ace85"
      },
      "source": [
        "# download samples\n",
        "# !wget -O assets/samples.zip \"https://1drv.ws/u/s!AjjUqiJZsj8whLobQPpoxo2hfhURrA?e=EUyIC2\"\n",
        "!wget -O assets/samples.zip  \"http://101.32.75.151:12345/iper_plus_plus_latest_samples.zip\"\n",
        "!unzip -o assets/samples.zip -d  assets\n",
        "!rm assets/samples.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-22 14:52:19--  http://101.32.75.151:12345/iper_plus_plus_latest_samples.zip\n",
            "Connecting to 101.32.75.151:12345... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: ./iper_plus_plus_1.0.0_samples.zip [following]\n",
            "--2022-09-22 14:52:19--  http://101.32.75.151:12345/iper_plus_plus_1.0.0_samples.zip\n",
            "Reusing existing connection to 101.32.75.151:12345.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://101.32.75.151:10086/assets/samples.zip [following]\n",
            "--2022-09-22 14:52:19--  http://101.32.75.151:10086/assets/samples.zip\n",
            "Connecting to 101.32.75.151:10086... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.dm.files.1drv.com/y4mPtfIpeXo_26sH5L7g5DNRMASDr_SY2Z2t6btMDrM5P_2JclzEGT2l7qkiPS-i4WPhfnoTjGYE0UkTz4492a5pcnYCrScO-Epy3kaVJqsn2FocoMWbuZH9h9vubIRz0PQDdxtNJNDlNAnUrel1EQnY6hSTlpzA5JTpoNGCnZFHQmhpd1Sc3UQd6W6cmf-O5esgHyaCdWmionWNpcKEnvqS7ma6jVmQr3jV6c6dwai3faLo4KSxHUdPNNQSTMwDohA [following]\n",
            "--2022-09-22 14:52:19--  https://public.dm.files.1drv.com/y4mPtfIpeXo_26sH5L7g5DNRMASDr_SY2Z2t6btMDrM5P_2JclzEGT2l7qkiPS-i4WPhfnoTjGYE0UkTz4492a5pcnYCrScO-Epy3kaVJqsn2FocoMWbuZH9h9vubIRz0PQDdxtNJNDlNAnUrel1EQnY6hSTlpzA5JTpoNGCnZFHQmhpd1Sc3UQd6W6cmf-O5esgHyaCdWmionWNpcKEnvqS7ma6jVmQr3jV6c6dwai3faLo4KSxHUdPNNQSTMwDohA\n",
            "Resolving public.dm.files.1drv.com (public.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to public.dm.files.1drv.com (public.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251759768 (240M) [application/zip]\n",
            "Saving to: ‘assets/samples.zip’\n",
            "\n",
            "assets/samples.zip  100%[===================>] 240.10M  14.7MB/s    in 24s     \n",
            "\n",
            "2022-09-22 14:52:44 (10.1 MB/s) - ‘assets/samples.zip’ saved [251759768/251759768]\n",
            "\n",
            "Archive:  assets/samples.zip\n",
            "  inflating: assets/samples/references/aini.mp4  \n",
            "  inflating: assets/samples/references/akGexYZug2Q_2.mp4.mp4  \n",
            "  inflating: assets/samples/references/akun_1.mp4  \n",
            "  inflating: assets/samples/references/akun_2.mp4  \n",
            "  inflating: assets/samples/references/Av37667655_2.mp4  \n",
            "  inflating: assets/samples/references/bantangzhuyi_1.mp4  \n",
            "  inflating: assets/samples/references/BV1rD4y1Q72j_2.mp4  \n",
            "  inflating: assets/samples/references/chengfengpolang_1.mp4  \n",
            "  inflating: assets/samples/references/kuailechongbai_boy.mp4  \n",
            "  inflating: assets/samples/references/mabaoguo.mp4  \n",
            "  inflating: assets/samples/references/mabaoguo_short.mp4  \n",
            "   creating: assets/samples/sources/001_18_1/\n",
            "  inflating: assets/samples/sources/001_18_1/000.jpg  \n",
            "  inflating: assets/samples/sources/001_18_1/190.jpg  \n",
            "   creating: assets/samples/sources/001_19_1/\n",
            "  inflating: assets/samples/sources/001_19_1/000.jpg  \n",
            "  inflating: assets/samples/sources/001_19_1/120.jpg  \n",
            "   creating: assets/samples/sources/5NJIkUmh_h0/\n",
            " extracting: assets/samples/sources/5NJIkUmh_h0/0001.PNG  \n",
            "   creating: assets/samples/sources/91iZ9x8NI0S/\n",
            "  inflating: assets/samples/sources/91iZ9x8NI0S/frame_00000026.png  \n",
            "   creating: assets/samples/sources/afan_3/\n",
            "   creating: assets/samples/sources/afan_3/afan_3/\n",
            "  inflating: assets/samples/sources/afan_3/afan_3/IMG_7129.JPG  \n",
            "  inflating: assets/samples/sources/afan_3/afan_3/IMG_7131.JPG  \n",
            "  inflating: assets/samples/sources/afan_3/IMG_7128.JPG  \n",
            "   creating: assets/samples/sources/afan_6/\n",
            "   creating: assets/samples/sources/afan_6/afan_6/\n",
            "   creating: assets/samples/sources/afan_6/afan_6=ns=2/\n",
            "  inflating: assets/samples/sources/afan_6/afan_6=ns=2/IMG_7218.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6=ns=2/IMG_7221.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7218.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7219.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7220.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7221.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7222.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7223.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7224.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/IMG_7217.JPG  \n",
            "   creating: assets/samples/sources/axing_1/\n",
            "  inflating: assets/samples/sources/axing_1/000.jpg  \n",
            "  inflating: assets/samples/sources/axing_1/125.jpg  \n",
            "   creating: assets/samples/sources/axing_7/\n",
            "   creating: assets/samples/sources/axing_7/axing_7/\n",
            "   creating: assets/samples/sources/axing_7/axing_7=2/\n",
            "  inflating: assets/samples/sources/axing_7/axing_7=2/IMG_7234.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7=2/IMG_7237.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7234.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7235.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7236.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7237.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7238.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7239.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/IMG_7233.JPG  \n",
            "   creating: assets/samples/sources/caixukun2/\n",
            "  inflating: assets/samples/sources/caixukun2/caixukun_front_full_size.png  \n",
            "  inflating: assets/samples/sources/caixukun2/frame00000597.png  \n",
            "   creating: assets/samples/sources/cartoon_12/\n",
            "  inflating: assets/samples/sources/cartoon_12/0.jpg  \n",
            "  inflating: assets/samples/sources/cartoon_12/1.jpg  \n",
            " extracting: assets/samples/sources/donald_trump_2/00000.PNG  \n",
            "   creating: assets/samples/sources/fange_1/\n",
            "   creating: assets/samples/sources/fange_1/fange_1_ns=2/\n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=2/IMG_7227.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=2/IMG_7230.JPG  \n",
            "   creating: assets/samples/sources/fange_1/fange_1_ns=6/\n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7227.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7228.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7229.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7230.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7231.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7232.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/IMG_7225.JPG  \n",
            "   creating: assets/samples/sources/google_1/\n",
            "  inflating: assets/samples/sources/google_1/0.jpg  \n",
            "   creating: assets/samples/sources/google_2/\n",
            "  inflating: assets/samples/sources/google_2/01.jpg  \n",
            "  inflating: assets/samples/sources/google_2/02.png  \n",
            "   creating: assets/samples/sources/mabaoguo_v2/\n",
            "  inflating: assets/samples/sources/mabaoguo_v2/mabaoguo_1.png  \n",
            "  inflating: assets/samples/sources/mabaoguo_v2/mabaoguo_back_full_size.png  \n",
            "  inflating: assets/samples/sources/skirts3.jpg  \n",
            "   creating: assets/samples/sources/stephen_curry/\n",
            "  inflating: assets/samples/sources/stephen_curry/0000.webp  \n",
            "   creating: assets/samples/sources/WabSbZp9dII_1/\n",
            " extracting: assets/samples/sources/WabSbZp9dII_1/frame_00011159.png  \n",
            " extracting: assets/samples/sources/wangyibo_2.jpg  \n",
            "   creating: assets/samples/sources/wtW2R7hTImA_1/\n",
            "  inflating: assets/samples/sources/wtW2R7hTImA_1/frame_00000920.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffbq0leDOUGS"
      },
      "source": [
        "# Run Motion Imitation Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9KymQM8z6sH",
        "outputId": "cb658c6d-0251-4a30-c538-a7694b3b0009"
      },
      "source": [
        "cd /content/iPERCore/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iPERCore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the reference videos"
      ],
      "metadata": {
        "id": "R_9SbDH0rs_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ./assets/samples/references/ \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2hNdLUJkZ18",
        "outputId": "1faeebac-3fea-4e13-f917-b7022a30bf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 184452\n",
            "drwxr-xr-x 2 root root     4096 Sep 22 14:52 .\n",
            "drwxr-xr-x 4 root root     4096 Sep 22 14:44 ..\n",
            "-rw-r--r-- 1 root root 43754857 Dec  5  2020 aini.mp4\n",
            "-rw-r--r-- 1 root root 10932339 Dec  5  2020 akGexYZug2Q_2.mp4.mp4\n",
            "-rw-r--r-- 1 root root  1534857 Dec  5  2020 akun_1.mp4\n",
            "-rw-r--r-- 1 root root  3409469 Dec  5  2020 akun_2.mp4\n",
            "-rw-r--r-- 1 root root 20182646 Dec  5  2020 Av37667655_2.mp4\n",
            "-rw-r--r-- 1 root root 14406191 Dec  5  2020 bantangzhuyi_1.mp4\n",
            "-rw-r--r-- 1 root root 40443168 Dec  5  2020 BV1rD4y1Q72j_2.mp4\n",
            "-rw-r--r-- 1 root root 16541753 Dec  5  2020 chengfengpolang_1.mp4\n",
            "-rw-r--r-- 1 root root 11130242 Sep 22 14:44 Fortnite_orange_justice.mp4\n",
            "-rw-r--r-- 1 root root  9343174 Dec  5  2020 kuailechongbai_boy.mp4\n",
            "-rw-r--r-- 1 root root  7933882 Dec  5  2020 mabaoguo.mp4\n",
            "-rw-r--r-- 1 root root  9232298 Dec  5  2020 mabaoguo_short.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop the video (aini.mp4)"
      ],
      "metadata": {
        "id": "_NY918W_ryc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i ./assets/samples/references/aini.mp4  -ss 00:02:00 -to 00:02:30 -c:v copy -c:a copy ./assets/samples/references/aini_short.mp4\n",
        "!ls -al ./assets/samples/references/"
      ],
      "metadata": {
        "id": "DQa1LxZ3q2Ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f379def-d2c8-4b55-9b28-9e285fea8bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './assets/samples/references/aini.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.45.100\n",
            "  Duration: 00:03:32.40, start: 0.000000, bitrate: 1648 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x1000 [SAR 1:1 DAR 18:25], 1510 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Output #0, mp4, to './assets/samples/references/aini_short.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x1000 [SAR 1:1 DAR 18:25], q=2-31, 1510 kb/s, 30 fps, 30 tbr, 15360 tbn, 15360 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #0:1 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=  752 fps=0.0 q=-1.0 Lsize=    5529kB time=00:00:29.99 bitrate=1510.0kbits/s speed=1.07e+03x    \n",
            "video:5029kB audio:471kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.526385%\n",
            "total 189984\n",
            "drwxr-xr-x 2 root root     4096 Sep 22 14:53 .\n",
            "drwxr-xr-x 4 root root     4096 Sep 22 14:44 ..\n",
            "-rw-r--r-- 1 root root 43754857 Dec  5  2020 aini.mp4\n",
            "-rw-r--r-- 1 root root  5661454 Sep 22 14:53 aini_short.mp4\n",
            "-rw-r--r-- 1 root root 10932339 Dec  5  2020 akGexYZug2Q_2.mp4.mp4\n",
            "-rw-r--r-- 1 root root  1534857 Dec  5  2020 akun_1.mp4\n",
            "-rw-r--r-- 1 root root  3409469 Dec  5  2020 akun_2.mp4\n",
            "-rw-r--r-- 1 root root 20182646 Dec  5  2020 Av37667655_2.mp4\n",
            "-rw-r--r-- 1 root root 14406191 Dec  5  2020 bantangzhuyi_1.mp4\n",
            "-rw-r--r-- 1 root root 40443168 Dec  5  2020 BV1rD4y1Q72j_2.mp4\n",
            "-rw-r--r-- 1 root root 16541753 Dec  5  2020 chengfengpolang_1.mp4\n",
            "-rw-r--r-- 1 root root 11130242 Sep 22 14:44 Fortnite_orange_justice.mp4\n",
            "-rw-r--r-- 1 root root  9343174 Dec  5  2020 kuailechongbai_boy.mp4\n",
            "-rw-r--r-- 1 root root  7933882 Dec  5  2020 mabaoguo.mp4\n",
            "-rw-r--r-- 1 root root  9232298 Dec  5  2020 mabaoguo_short.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJskZDTiEKMB"
      },
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import platform\n",
        "import argparse\n",
        "import time\n",
        "import sys\n",
        "import subprocess\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo9IgZwsOmBd"
      },
      "source": [
        "## Details of Config\n",
        " - gpu_ids (str): the gpu_ids, default is \"0\";\n",
        " - image_size (int): the image size, default is 512;\n",
        " - num_source (int): the number of source images for Attention, default is 2. Large needs more GPU memory;\n",
        " - assets_dir (str): the assets directory. This is very important, and there are the configurations and all pre-trained checkpoints;\n",
        " - output_dir (str): the output directory;\n",
        "\n",
        " - src_path (str): the source input information. \n",
        "       All source paths and it supports multiple paths, uses \"|\" as the separator between all paths. \n",
        "       The format is \"src_path_1|src_path_2|src_path_3\". \n",
        "       \n",
        "       Each src_input is \"path?=path1,name?=name1,bg_path?=bg_path1\". \n",
        "       \n",
        "       It must contain 'path'. If 'name' and 'bg_path' are empty, they will be ignored.\n",
        "\n",
        "       The 'path' could be an image path, a path of a directory contains source images, and a video path.\n",
        "\n",
        "       The 'name' is the rename of this source input, if it is empty, we will ignore it, and use the filename of the path.\n",
        "\n",
        "       The 'bg_path' is the actual background path if provided, otherwise we will ignore it.\n",
        "       \n",
        "       There are several examples of formated source paths,\n",
        "\n",
        "        1. \"path?=path1,name?=name1,bg_path?=bg_path1|path?=path2,name?=name2,bg_path?=bg_path2\",\n",
        "        this input will be parsed as [{path: path1, name: name1, bg_path:bg_path1},\n",
        "        {path: path2, name: name2, bg_path: bg_path2}];\n",
        "\n",
        "        2. \"path?=path1,name?=name1|path?=path2,name?=name2\", this input will be parsed as\n",
        "        [{path: path1, name:name1}, {path: path2, name: name2}];\n",
        "\n",
        "        3. \"path?=path1\", this input will be parsed as [{path: path1}].\n",
        "\n",
        "        4. \"path1\", this will be parsed as [{path: path1}].\n",
        "\n",
        " - ref_path (str): the reference input information.\n",
        "       \n",
        "       All reference paths. It supports multiple paths, and uses \"|\" as the separator between all paths.\n",
        "       The format is \"ref_path_1|ref_path_2|ref_path_3\".\n",
        "\n",
        "       Each ref_path is \"path?=path1,name?=name1,audio?=audio_path1,fps?=30,pose_fc?=300,cam_fc?=150\".\n",
        "\n",
        "       It must contain 'path', and others could be empty, and they will be ignored.\n",
        "\n",
        "       The 'path' could be an image path, a path of a directory contains images of a same person, and a video path.\n",
        "\n",
        "       The 'name' is the rename of this source input, if it is empty, we will ignore it, and use the filename of the path.\n",
        "\n",
        "       The 'audio' is the audio path, if it is empty, we will ignore it. If the 'path' is a video,\n",
        "        you can ignore this, and we will firstly extract the audio information of this video (if it has audio channel).\n",
        "\n",
        "       The 'fps' is fps of the final outputs, if it is empty, we will set it as the default fps 25.\n",
        "\n",
        "       The 'pose_fc' is the smooth factor of the temporal poses. The smaller of this value, the smoother of the temporal poses. If it is empty, we will set it as the default 300. In the most cases, using the default 300 is enough, and if you find the poses of the outputs are not stable, you can decrease this value. Otherwise, if you find the poses of the outputs are over stable, you can increase this value.\n",
        "\n",
        "       The 'cam_fc' is the smooth factor of the temporal cameras (locations in the image space). The smaller of this value, the smoother of the locations in sequences. If it is empty, we will set it as the default 150. In the most cases, the default 150 is enough.\n",
        "\n",
        "       There are several examples of formated reference paths,\n",
        "\n",
        "        1. \"path?=path1,name?=name1,audio?=audio_path1,fps?=30,pose_fc?=300,cam_fc?=150|\n",
        "            path?=path2,name?=name2,audio?=audio_path2,fps?=25,pose_fc?=450,cam_fc?=200\",\n",
        "            this input will be parsed as\n",
        "            [{path: path1, name: name1, audio: audio_path1, fps: 30, pose_fc: 300, cam_fc: 150},\n",
        "             {path: path2, name: name2, audio: audio_path2, fps: 25, pose_fc: 450, cam_fc: 200}]\n",
        "\n",
        "        2. \"path?=path1,name?=name1, pose_fc?=450|path?=path2,name?=name2\", this input will be parsed as\n",
        "        [{path: path1, name: name1, fps: 25, pose_fc: 450, cam_fc: 150},\n",
        "         {path: path2, name: name2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        3. \"path?=path1|path?=path2\", this input will be parsed as\n",
        "        [{path: path1, fps:25, pose_fc: 300, cam_fc: 150}, {path: path2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        4. \"path1|path2\", this input will be parsed as\n",
        "        [{path: path1, fps:25, pose_fc: 300, cam_fc: 150}, {path: path2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        5. \"path1\", this will be parsed as [{path: path1, fps: 25, pose_fc: 300, cam_fc: 150}]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vme5bj8xmfsC"
      },
      "source": [
        "## Run Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNWVyAaeOhHP"
      },
      "source": [
        "# the gpu ids\n",
        "gpu_ids = \"0\"\n",
        "\n",
        "# the image size\n",
        "image_size = 512\n",
        "\n",
        "# the default number of source images, it will be updated if the actual number of sources <= num_source\n",
        "num_source = 2\n",
        "\n",
        "# the assets directory. This is very important, please download it from `one_drive_url` firstly.\n",
        "assets_dir = \"/content/iPERCore/assets\"\n",
        "\n",
        "# the output directory.\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# the model id of this case. This is a random model name.\n",
        "# model_id = \"model_\" + str(time.time())\n",
        "\n",
        "# # This is a specific model name, and it will be used if you do not change it.\n",
        "# model_id = \"axing_1\"\n",
        "\n",
        "# symlink from the actual assets directory to this current directory\n",
        "work_asserts_dir = os.path.join(\"./assets\")\n",
        "if not os.path.exists(work_asserts_dir):\n",
        "    os.symlink(osp.abspath(assets_dir), osp.abspath(work_asserts_dir),\n",
        "               target_is_directory=(platform.system() == \"Windows\"))\n",
        "\n",
        "cfg_path = osp.join(work_asserts_dir, \"configs\", \"deploy.toml\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGKRtrNgZ14V"
      },
      "source": [
        "### Run the sample case\n",
        "In this case, there is only a frontal body image as the source inputs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a sample pic from the local\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the file name\n",
        "file_name = list(uploaded.keys())[0]\n",
        "print(file_name)\n",
        "file_string = os.path.splitext(file_name)[0]\n",
        "print(file_string)\n",
        "\n",
        "# check the pic file name & path\n",
        "cwd = os.getcwd()\n",
        "# the source input information, here \\\" is escape character of double duote \"\n",
        "src_path = f\"\\\"path?={cwd}/{file_name},name?={file_string}\\\"\"\n",
        "print(src_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "_1hlG9pyEEas",
        "outputId": "26adb1cf-76b4-400d-8665-f13bb2337aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-494241a7-e558-42e3-bfa5-9fd6c3da3a73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-494241a7-e558-42e3-bfa5-9fd6c3da3a73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving retrato.jpg to retrato (4).jpg\n",
            "retrato.jpg\n",
            "retrato\n",
            "\"path?=/content/iPERCore/retrato.jpg,name?=retrato\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETaQCD0t1qqO",
        "outputId": "956e8e68-fe0b-49bd-87be-adcb50afcf89"
      },
      "source": [
        "# The model name is the file name of the uploaded file\n",
        "model_id = file_string\n",
        "\n",
        "# get the ref video - it should be in the folder \"/content/iPERCore/assets/samples/references/\"\n",
        "ref_vidname = \"aini_short\"\n",
        "ref_path = f\"\\\"path?=/content/iPERCore/assets/samples/references/{ref_vidname}.mp4,\" \\\n",
        "            f\"name?={ref_vidname},\" \\\n",
        "             \"pose_fc?=300\\\"\"\n",
        "print(ref_path)\n",
        "\n",
        "!python -m iPERCore.services.run_imitator  \\\n",
        "  --gpu_ids     $gpu_ids       \\\n",
        "  --num_source  $num_source    \\\n",
        "  --image_size  $image_size    \\\n",
        "  --output_dir  $output_dir    \\\n",
        "  --model_id    $model_id      \\\n",
        "  --cfg_path    $cfg_path      \\\n",
        "  --src_path    $src_path      \\\n",
        "  --ref_path    $ref_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"path?=/content/iPERCore/assets/samples/references/aini_short.mp4,name?=aini_short,pose_fc?=300\"\n",
            "ffprobe -show_entries stream=codec_type -of json /content/iPERCore/assets/samples/references/aini_short.mp4 -loglevel error\n",
            "ffmpeg -y -i /content/iPERCore/assets/samples/references/aini_short.mp4 -ab 160k -ac 2 -ar 44100 -vn ./results/primitives/aini_short/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /content/iPERCore/assets/samples/references/aini_short.mp4\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/iPERCore/retrato.jpg\n",
            "\tbg_path: \n",
            "\tname: retrato\n",
            "primitives_dir: ./results/primitives/retrato\n",
            "processed_dir: ./results/primitives/retrato/processed\n",
            "vid_info_path: ./results/primitives/retrato/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/iPERCore/assets/samples/references/aini_short.mp4\n",
            "\tbg_path: \n",
            "\tname: aini_short\n",
            "\taudio: ./results/primitives/aini_short/processed/audio.mp3\n",
            "\tfps: 30.0\n",
            "\tpose_fc: 300.0\n",
            "\tcam_fc: 100\n",
            "\teffect: \n",
            "primitives_dir: ./results/primitives/aini_short\n",
            "processed_dir: ./results/primitives/aini_short/processed\n",
            "vid_info_path: ./results/primitives/aini_short/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of ./results/primitives/retrato/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  3.03it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of ./results/primitives/retrato/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in ./results/primitives/retrato/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 15.26it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in ./results/primitives/retrato/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in./results/primitives/retrato/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to run human matting in ./results/primitives/retrato/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  2.96it/s]\n",
            "\t1.4 Preprocessing, finish run human matting.\n",
            "\t1.5 Preprocessing, running Preprocessor to find 25 candidates front images in ./results/primitives/retrato/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 23.32it/s]\n",
            "\t1.5 Preprocessing, finish find the front images ....\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to ./results/primitives/retrato/processed/visual.mp4 ...\n",
            "100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "ffmpeg -y -i ./results/primitives/retrato/processed/visual.mp4.avi -vcodec h264 ./results/primitives/retrato/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to ./results/primitives/retrato/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/content/iPERCore/assets/samples/references/aini_short.mp4 Writing frames to file\n",
            "ffmpeg -i /content/iPERCore/assets/samples/references/aini_short.mp4 -start_number 0 ./results/primitives/aini_short/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/iPERCore/assets/samples/references/aini_short.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:30.02, start: 0.000000, bitrate: 1508 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x1000 [SAR 1:1 DAR 18:25], 1643 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to './results/primitives/aini_short/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(eng): Video: png, rgb24, 720x1000 [SAR 1:1 DAR 18:25], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=  901 fps= 24 q=-0.0 Lsize=N/A time=00:00:30.03 bitrate=N/A dup=150 drop=0 speed=0.81x    \n",
            "video:606450kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of ./results/primitives/aini_short/processed/orig_images...\n",
            "100% 901/901 [01:12<00:00, 12.38it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of ./results/primitives/aini_short/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in ./results/primitives/aini_short/processed/orig_images by estimated boxes ...\n",
            "901it [00:18, 49.56it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in ./results/primitives/aini_short/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in./results/primitives/aini_short/processed/images ...\n",
            "100% 29/29 [00:18<00:00,  1.57it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "100% 1/1 [00:00<00:00,  4.43it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 2. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [02:08<00:00,  1.29s/it]\n",
            "saving the personalized model in ./results/models/retrato/personalized.pth\n",
            "Step 2: personalization done, saved in ./results/models/retrato/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from ./results/models/retrato/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "pred_: 100% 901/901 [02:13<00:00,  6.76it/s]\n",
            "901it [00:16, 53.92it/s]\n",
            "ffmpeg -y -i ./results/primitives/retrato/synthesis/imitations/retrato-aini_short.mp4.avi -i ./results/primitives/aini_short/processed/audio.mp3 -vcodec h264 -shortest -strict -2 ./results/primitives/retrato/synthesis/imitations/retrato-aini_short.mp4 -loglevel quiet\n",
            "----------------------MetaOutput----------------------\n",
            "retrato imitates aini_short in ./results/primitives/retrato/synthesis/imitations/retrato-aini_short.mp4\n",
            "------------------------------------------------------\n",
            "Step 3: running imitator done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_path = f\"\\./results/primitives/{file_string}/synthesis/imitations/{file_string}-{ref_vidname}.mp4\"\n"
      ],
      "metadata": {
        "id": "V7WxOsQ8_J9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mfjZuFMjVJlE",
        "outputId": "e31dd852-e17b-4a09-9adf-9377d3f93601"
      },
      "source": [
        "\n",
        "# cropping the video \n",
        "!ffmpeg -i $result_path -filter:v \"crop=312:512:1144:0\" -c:a copy result.mp4\n",
        "# change mp4 to gif\n",
        "!ffmpeg -ss 4 -t 14 -i result.mp4 -vf \"fps=10,scale=300:-1:flags=lanczos\" -loop 0 result.gif\n",
        "# Download the created video to the local\n",
        "files.download(\"result.gif\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './results/primitives/retrato/synthesis/imitations/retrato-aini_short.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:30.04, start: 0.000000, bitrate: 1103 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1556x512 [SAR 1:1 DAR 389:128], 966 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "File 'result.mp4' already exists. Overwrite ? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
            "  Stream #0:1 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mprofile High, level 2.1\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'result.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 312x512 [SAR 1:1 DAR 39:64], q=-1--1, 30 fps, 15360 tbn, 30 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "frame=  901 fps=130 q=-1.0 Lsize=    1644kB time=00:00:30.00 bitrate= 448.9kbits/s speed=4.32x    \n",
            "video:1141kB audio:470kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.053301%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mframe I:4     Avg QP:19.04  size: 17458\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mframe P:237   Avg QP:22.50  size:  2456\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mframe B:660   Avg QP:29.03  size:   782\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mconsecutive B-frames:  1.3%  1.3%  5.0% 92.3%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mmb I  I16..4:  2.6% 90.6%  6.8%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mmb P  I16..4:  0.3%  4.3%  0.9%  P16..4: 17.6% 13.1%  6.9%  0.0%  0.0%    skip:56.9%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mmb B  I16..4:  0.0%  0.5%  0.1%  B16..8: 17.4%  6.9%  1.2%  direct: 0.9%  skip:72.9%  L0:46.5% L1:47.2% BI: 6.3%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0m8x8 transform intra:80.3% inter:73.1%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mcoded y,uvDC,uvAC intra: 76.5% 83.2% 42.0% inter: 7.6% 8.0% 0.3%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mi16 v,h,dc,p: 37% 21% 12% 30%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 16% 16%  5%  7%  9%  7%  8%  7%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 15% 17%  5%  9%  9%  7%  6%  5%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mi8c dc,h,v,p: 43% 21% 26% 10%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mref P L0: 59.7% 11.2% 18.4% 10.7%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mref B L0: 88.6%  8.3%  3.1%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mref B L1: 96.1%  3.9%\n",
            "\u001b[1;36m[libx264 @ 0x559df2d90800] \u001b[0mkb/s:311.06\n",
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'result.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:30.04, start: 0.000000, bitrate: 448 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 312x512 [SAR 1:1 DAR 39:64], 311 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "File 'result.gif' already exists. Overwrite ? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> gif (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, gif, to 'result.gif':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: gif, bgr8, 300x492 [SAR 1599:1600 DAR 39:64], q=2-31, 200 kb/s, 10 fps, 100 tbn, 10 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 gif\n",
            "frame=  140 fps=0.0 q=-0.0 Lsize=    2982kB time=00:00:13.91 bitrate=1756.0kbits/s speed=18.4x    \n",
            "video:2980kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.062957%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_298d1bd5-62e4-40b4-9a13-e0a57033e0af\", \"result.gif\", 3053232)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About custom inputs"
      ],
      "metadata": {
        "id": "cVG2bxgiCRcr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7oH0Np6bpgb"
      },
      "source": [
        "### Run your custom inputs\n",
        "You can upload your own custom source images, and reference videos with the followings guidelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH9QHYKUiqXH"
      },
      "source": [
        "#### Source Guidelines:\n",
        " - Try to capture the source images with the same static background without too complex scene structures. If possible, we recommend using the\n",
        "actual background.\n",
        " - The person in the source images holds an A-pose for introducing the most visible textures.\n",
        " - It is recommended to capture the source images in an environment without too much contrast in lighting conditions and lock auto-exposure and auto-focus of the camera."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJg2YdjYiulk"
      },
      "source": [
        "#### Reference Guidelines:\n",
        "  - Make sure that there is only **one** person in the reference video. Since,currently, our system does not support multiple people tracking. If there are multiple people, you need firstly use other video processing tools to crop the video.\n",
        "  - Make sure that capture the video with full body person. Half body will result in bad results.\n",
        "  - Try to capture the video with the static camera lens, and make sure that there is no too much zoom-in, zoom-out, panning, lens swichtings, and camera transitions. If there are multiple lens switchting and camera transitions, you need firstly use other video processing tools to crop the video."
      ]
    }
  ]
}